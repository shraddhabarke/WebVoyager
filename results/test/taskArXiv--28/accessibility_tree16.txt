[5914] RootWebArea '[2309.16770] Persona-Coded Poly-Encoder: Persona-Guided Multi-Stream Conversational Sentence Scoring' focused: True url: https://arxiv.org/abs/2309.16770
	[6032] StaticText 'Skip to main content'
	[6040] link 'Cornell University' url: https://www.cornell.edu/
		[5918] image 'Cornell University' url: https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg
	[6047] StaticText 'We gratefully acknowledge support from the Simons Foundation, '
	[6048] link 'member institutions' url: https://info.arxiv.org/about/ourmembers.html
	[6050] StaticText ', and all contributors.'
	[6052] link 'Donate' url: https://info.arxiv.org/about/donate.html
	[6063] link 'arxiv logo' url: https://arxiv.org/
		[5919] image 'arxiv logo' url: https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg
	[6066] StaticText '>'
	[6068] link 'cs' url: https://arxiv.org/list/cs/recent
	[6073] StaticText 'arXiv:2309.16770'
	[5888] textbox 'Search term or terms' required: False
	[6084] link 'Help' url: https://info.arxiv.org/help
	[6086] StaticText ' | '
	[6087] link 'Advanced Search' url: https://arxiv.org/search/advanced
	[5889] combobox 'Field to search' hasPopup: menu expanded: False
	[6147] button 'Search'
	[6235] main ''
		[6246] heading 'Computer Science > Computation and Language'
		[6262] StaticText '[Submitted on 28 Sep 2023 ('
		[6263] link 'v1' url: https://arxiv.org/abs/2309.16770v1
		[6265] StaticText '), last revised 1 Dec 2023 (this version, v2)]'
		[6267] heading 'Persona-Coded Poly-Encoder: Persona-Guided Multi-Stream Conversational Sentence Scoring'
		[6275] link 'Junfeng Liu' url: https://arxiv.org/search/cs?searchtype=author&query=Liu,+J
		[6278] link 'Christopher Symons' url: https://arxiv.org/search/cs?searchtype=author&query=Symons,+C
		[6280] StaticText ', '
		[6281] link 'Ranga Raju Vatsavai' url: https://arxiv.org/search/cs?searchtype=author&query=Vatsavai,+R+R
		[5920] blockquote ''
			[6296] StaticText 'Recent advances in machine learning and deep learning have led to the widespread use of Conversational AI in many practical applications. However, it is still very challenging to leverage auxiliary information that can provide conversational context or personalized tuning to improve the quality of conversations. For example, there has only been limited research on using an individuals persona information to improve conversation quality, and even state-of-the-art conversational AI techniques are unable to effectively leverage signals from heterogeneous sources of auxiliary data, such as multi-modal interaction data, demographics, SDOH data, etc. In this paper, we present a novel Persona-Coded Poly-Encoder method that leverages persona information in a multi-stream encoding scheme to improve the quality of response generation for conversations. To show the efficacy of the proposed method, we evaluate our method on two different persona-based conversational datasets, and compared against two state-of-the-art methods. Our experimental results and analysis demonstrate that our method can improve conversation quality over the baseline method Poly-Encoder by 3.32% and 2.94% in terms of BLEU score and HR@1, respectively. More significantly, our method offers a path to better utilization of multi-modal data in conversational tasks. Lastly, our study outlines several challenges and future research directions for advancing personalized conversational AI technology.'
		[6302] table 'Additional metadata'
			[6305] row ''
				[6307] cell 'Comments:'
				[6310] cell 'The 35th IEEE International Conference on Tools with Artificial Intelligence (ICTAI)'
			[6314] row ''
				[6316] cell 'Subjects:'
				[6319] cell 'Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)'
			[6325] row ''
				[6327] cell 'Cite as:'
				[6330] cell 'arXiv:2309.16770 [cs.CL]'
					[6332] link 'arXiv:2309.16770' url: https://arxiv.org/abs/2309.16770
			[6337] row ''
				[6339] cell '\xa0'
				[6342] cell '(or arXiv:2309.16770v2 [cs.CL] for this version)'
					[6346] link 'arXiv:2309.16770v2' url: https://arxiv.org/abs/2309.16770v2
			[6352] row ''
				[6354] cell '\xa0'
				[6357] cell 'https://doi.org/10.48550/arXiv.2309.16770 Focus to learn more'
					[6359] link 'https://doi.org/10.48550/arXiv.2309.16770' url: https://doi.org/10.48550/arXiv.2309.16770
					[6363] button 'Focus to learn more' describedby: more-info-desc-1
			[6382] row ''
				[6384] cell 'Journal\xa0reference:'
				[6387] cell '2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)'
			[6391] row ''
				[6393] cell 'Related DOI:'
					[6395] Abbr 'Digital Object Identifier'
				[6399] cell 'https://doi.org/10.1109/ICTAI59109.2023.00044 Focus to learn more'
					[6400] link 'https://doi.org/10.1109/ICTAI59109.2023.00044' url: https://doi.org/10.1109/ICTAI59109.2023.00044
					[6407] button 'Focus to learn more' describedby: more-info-desc-1
		[6432] heading 'Submission history'
		[6434] StaticText 'From: Junfeng Liu ['
		[6435] link 'view email' url: https://arxiv.org/show-email/2dbd7251/2309.16770
		[6441] link '[v1]' url: https://arxiv.org/abs/2309.16770v1
		[6443] StaticText ' Thu, 28 Sep 2023 18:07:01 UTC (402 KB)'
		[6447] StaticText '[v2]'
		[6448] StaticText ' Fri, 1 Dec 2023 18:45:12 UTC (403 KB)'
		[6464] heading 'Access Paper:'
		[6472] link 'View PDF' describedby: download-button-info url: https://arxiv.org/pdf/2309.16770 keyshortcuts: Alt+f
		[6475] link 'HTML (experimental)' url: https://arxiv.org/html/2309.16770v2
		[6478] link 'TeX Source' url: https://arxiv.org/src/2309.16770
		[6481] link 'Other Formats' url: https://arxiv.org/format/2309.16770
		[6485] link 'view license' url: http://creativecommons.org/licenses/by-nc-nd/4.0/
		[6496] StaticText 'Current browse context:'
		[6498] StaticText 'cs.CL'
		[6504] link '<\xa0prev' url: https://arxiv.org/prevnext?id=2309.16770&function=prev&context=cs.CL keyshortcuts: Alt+p
		[6509] StaticText '\xa0 | \xa0'
		[6513] link 'next\xa0>' url: https://arxiv.org/prevnext?id=2309.16770&function=next&context=cs.CL keyshortcuts: Alt+n
		[6520] link 'new' url: https://arxiv.org/list/cs.CL/new
		[6526] link 'recent' url: https://arxiv.org/list/cs.CL/recent
		[6530] StaticText '| '
		[6531] link '2023-09' url: https://arxiv.org/list/cs.CL/2023-09
		[6535] StaticText 'Change to browse by:'
		[6538] link 'cs' url: https://arxiv.org/abs/2309.16770?context=cs
		[6542] link 'cs.AI' url: https://arxiv.org/abs/2309.16770?context=cs.AI
		[6546] link 'cs.LG' url: https://arxiv.org/abs/2309.16770?context=cs.LG
		[6555] heading 'References & Citations'
		[6561] link 'NASA ADS' url: https://ui.adsabs.harvard.edu/abs/arXiv:2309.16770
		[6564] link 'Google Scholar' url: https://scholar.google.com/scholar_lookup?arxiv_id=2309.16770
		[6568] link 'Semantic Scholar' url: https://api.semanticscholar.org/arXiv:2309.16770
		[6581] StaticText 'Export BibTeX Citation'
		[6617] heading 'Bookmark'
		[6619] link 'BibSonomy logo' url: http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2309.16770&description=Persona-Coded%20Poly-Encoder:%20Persona-Guided%20Multi-Stream%20Conversational%20Sentence%20Scoring
			[5916] image 'BibSonomy logo' url: https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png
		[6623] link 'Reddit logo' url: https://reddit.com/submit?url=https://arxiv.org/abs/2309.16770&title=Persona-Coded%20Poly-Encoder:%20Persona-Guided%20Multi-Stream%20Conversational%20Sentence%20Scoring
			[5917] image 'Reddit logo' url: https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png
		[6638] StaticText 'Bibliographic Tools'
		[6642] heading 'Bibliographic and Citation Tools'
		[6658] StaticText 'Bibliographic Explorer Toggle'
		[6667] emphasis ''
			[6668] StaticText '('
			[6669] link 'What is the Explorer?' url: https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer
			[6671] StaticText ')'
		[6686] StaticText 'Connected Papers Toggle'
		[6695] emphasis ''
			[6696] StaticText '('
			[6697] link 'What is Connected Papers?' url: https://www.connectedpapers.com/about
			[6699] StaticText ')'
		[6713] StaticText 'Litmaps Toggle'
		[6722] emphasis ''
			[6723] StaticText '('
			[6724] link 'What is Litmaps?' url: https://www.litmaps.co/
			[6726] StaticText ')'
		[6741] StaticText 'scite.ai Toggle'
		[6748] StaticText 'scite Smart Citations'
		[6750] emphasis ''
			[6751] StaticText '('
			[6752] link 'What are Smart Citations?' url: https://www.scite.ai/
			[6754] StaticText ')'
		[6770] StaticText 'Code, Data, Media'
		[6988] StaticText 'Demos'
		[7088] StaticText 'Related Papers'
		[7197] StaticText 'About arXivLabs'
		[7243] link 'Which authors of this paper are endorsers?' url: https://arxiv.org/auth/show-endorsers/2309.16770
		[7245] StaticText ' | '
		[7246] link 'Disable MathJax' url: javascript:setMathjaxCookie()
		[7248] StaticText ' ('
		[7249] link 'What is MathJax?' url: https://info.arxiv.org/help/mathjax.html
	[7261] contentinfo ''
		[7263] navigation 'Secondary'
			[7276] link 'About' url: https://info.arxiv.org/about
			[7280] link 'Help' url: https://info.arxiv.org/help
			[7298] link 'Contact' url: https://info.arxiv.org/help/contact.html
			[7311] link 'Subscribe' url: https://info.arxiv.org/help/subscribe
			[7332] link 'Copyright' url: https://info.arxiv.org/help/license/index.html
			[7336] link 'Privacy Policy' url: https://info.arxiv.org/help/policies/privacy_policy.html
			[7346] link 'Web Accessibility Assistance' url: https://info.arxiv.org/help/web_accessibility.html
			[7353] link 'arXiv Operational Status ' url: https://status.arxiv.org/
			[7358] StaticText 'Get status notifications via '
			[7359] link 'email' url: https://subscribe.sorryapp.com/24846f03/email/new
			[7363] StaticText ' or '
			[7364] link 'slack' url: https://subscribe.sorryapp.com/24846f03/slack/new