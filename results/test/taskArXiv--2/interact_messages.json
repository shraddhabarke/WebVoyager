[
  {
    "role": "system",
    "content": "Imagine you are a robot browsing the web, just like humans. Now you need to complete a task. In each iteration, you will receive an Accessibility Tree with numerical label representing information about the page, then follow the guidelines and choose one of the following actions:\n1. Click a Web Element.\n2. Delete existing content in a textbox and then type content. \n3. Scroll up or down. Multiple scrolls are allowed to browse the webpage. Pay attention!! The default scroll is the whole window. If the scroll widget is located in a certain area of the webpage, then you have to specify a Web Element in that area. I would hover the mouse there and then scroll.\n4. Wait. Typically used to wait for unfinished webpage processes, with a duration of 5 seconds.\n5. Go back, returning to the previous webpage.\n6. Google, directly jump to the Google search page. When you can't find information in some websites, try starting over with Google.\n7. Answer. This action should only be chosen when all questions in the task have been solved.\n\nCorrespondingly, Action should STRICTLY follow the format:\n- Click [Numerical_Label]\n- Type [Numerical_Label]; [Content]\n- Scroll [Numerical_Label or WINDOW]; [up or down]\n- Wait\n- GoBack\n- Google\n- ANSWER; [content]\n\nKey Guidelines You MUST follow:\n* Action guidelines *\n1) To input text, NO need to click textbox first, directly type content. After typing, the system automatically hits `ENTER` key. Sometimes you should click the search button to apply search filters. Try to use simple language when searching.  \n2) You must Distinguish between textbox and search button, don't type content into the button! If no textbox is found, you may need to click the search button first before the textbox is displayed. \n3) Execute only one action per iteration. \n4) STRICTLY Avoid repeating the same action if the webpage remains unchanged. You may have selected the wrong web element or numerical label. Continuous use of the Wait is also NOT allowed.\n5) When a complex Task involves multiple questions or steps, select \"ANSWER\" only at the very end, after addressing all of these questions (steps). Flexibly combine your own abilities with the information in the web page. Double check the formatting requirements in the task when ANSWER. \n* Web Browsing Guidelines *\n1) Don't interact with useless web elements like Login, Sign-in, donation that appear in Webpages. Pay attention to Key Web Elements like search textbox and menu.\n2) Vsit video websites like YouTube is allowed BUT you can't play videos. Clicking to download PDF is allowed and will be analyzed by the Assistant API.\n3) Focus on the date in task, you must look for results that match the date. It may be necessary to find the correct year, month and day at calendar.\n4) Pay attention to the filter and sort functions on the page, which, combined with scroll, can help you solve conditions like 'highest', 'cheapest', 'lowest', 'earliest', etc. Try your best to find the answer that best fits the task.\n\nYour reply should strictly follow the format:\nThought: {Your brief thoughts (briefly summarize the info that will help ANSWER)}\nAction: {One Action format you choose}\n\nThen the User will provide:\nObservation: {Accessibility Tree of a web page}"
  },
  {
    "role": "user",
    "content": "Now given a task: Look up the most recent papers related to 'cs.CL', select one and show its abstract.  Please interact with https://arxiv.org/ and get the answer.Observation: An accessibility tree. (Omitted in context.)"
  },
  {
    "role": "assistant",
    "content": "Thought: Need to go to arXiv homepage to navigate to cs.CL recent list.\nAction: Click 138"
  },
  {
    "role": "user",
    "content": "Observation: An accessibility tree. (Omitted in context.)"
  },
  {
    "role": "assistant",
    "content": "Thought: Need to open the recent list for cs.CL. Click link 2980.\nAction: Click 2980"
  },
  {
    "role": "user",
    "content": "The action you have chosen cannot be exected. Please double-check if you have selected the wrong Numerical Label or Action or Action format. Then provide the revised Thought and Action.Observation: An accessibility tree. (Omitted in context.)"
  },
  {
    "role": "assistant",
    "content": "Thought: Ensure the cs.CL link is properly brought into view; then try clicking again. First, scroll a bit further down where the link is located.\nAction: Scroll WINDOW; down"
  },
  {
    "role": "user",
    "content": "Observation: An accessibility tree. (Omitted in context.)"
  },
  {
    "role": "assistant",
    "content": "Thought: The cs.CL \"Computing Research Repository Computation and Language\" link is visible with label 2980; clicking it will navigate to recent cs.CL papers.\nAction: Click 2980"
  },
  {
    "role": "user",
    "content": "Observation: please analyze the accessibility tree and give the Thought and Action.\n[3559] RootWebArea 'Computation and Language' focused: True url: https://arxiv.org/list/cs.CL/recent\n\t[3626] StaticText 'Skip to main content'\n\t[3634] link 'Cornell University' url: https://www.cornell.edu/\n\t\t[3560] image 'Cornell University' url: https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\n\t[3641] StaticText 'We gratefully acknowledge support from the Simons Foundation, '\n\t[3642] link 'member institutions' url: https://info.arxiv.org/about/ourmembers.html\n\t[3644] StaticText ', and all contributors.'\n\t[3646] link 'Donate' url: https://info.arxiv.org/about/donate.html\n\t[3657] link 'arxiv logo' url: https://arxiv.org/\n\t\t[3561] image 'arxiv logo' url: https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg\n\t[3660] StaticText '>'\n\t[3662] link 'cs.CL' url: https://arxiv.org/list/cs.CL/recent\n\t[3565] textbox 'Search term or terms' required: False\n\t[3675] link 'Help' url: https://info.arxiv.org/help\n\t[3677] StaticText ' | '\n\t[3678] link 'Advanced Search' url: https://arxiv.org/search/advanced\n\t[3566] combobox 'Field to search' hasPopup: menu expanded: False\n\t[3738] button 'Search'\n\t[3826] main ''\n\t\t[3834] heading 'Computation and Language'\n\t\t[3837] heading 'Authors and titles for recent submissions'\n\t\t[3843] ListMarker '• '\n\t\t[3845] link 'Tue, 29 Apr 2025' url: https://arxiv.org/list/cs.CL/recent?skip=0&show=50\n\t\t[3849] ListMarker '• '\n\t\t[3851] link 'Mon, 28 Apr 2025' url: https://arxiv.org/list/cs.CL/recent?skip=82&show=50\n\t\t[3855] ListMarker '• '\n\t\t[3857] link 'Fri, 25 Apr 2025' url: https://arxiv.org/list/cs.CL/recent?skip=124&show=50\n\t\t[3860] ListMarker '• '\n\t\t[3862] link 'Thu, 24 Apr 2025' url: https://arxiv.org/list/cs.CL/recent?skip=168&show=50\n\t\t[3866] ListMarker '• '\n\t\t[3868] link 'Wed, 23 Apr 2025' url: https://arxiv.org/list/cs.CL/recent?skip=217&show=50\n\t\t[3874] link 'new' url: https://arxiv.org/list/cs.CL/new\n\t\t[3876] StaticText ' changes'\n\t\t[3879] StaticText 'Total of 270 entries : '\n\t\t[3881] StaticText '1-50'\n\t\t[3883] link '51-100' url: https://arxiv.org/list/cs.CL/recent?skip=50&show=50\n\t\t[3886] link '101-150' url: https://arxiv.org/list/cs.CL/recent?skip=100&show=50\n\t\t[3889] link '151-200' url: https://arxiv.org/list/cs.CL/recent?skip=150&show=50\n\t\t[3893] StaticText '...'\n\t\t[3895] link '251-270' url: https://arxiv.org/list/cs.CL/recent?skip=250&show=50\n\t\t[3900] StaticText 'Showing up to 50 entries per page: '\n\t\t[3901] link 'fewer' url: https://arxiv.org/list/cs.CL/recent?skip=0&show=25\n\t\t[3903] StaticText ' | '\n\t\t[3904] link 'more' url: https://arxiv.org/list/cs.CL/recent?skip=0&show=100\n\t\t[3907] link 'all' url: https://arxiv.org/list/cs.CL/recent?skip=0&show=2000\n\t\t[3911] DescriptionList ''\n\t\t\t[3913] heading 'Tue, 29 Apr 2025 (showing first 50 of 82 entries )'\n\t\t\t[3916] term '[1] arXiv:2504.20039 [ pdf , html , other ]'\n\t\t\t\t[3921] link 'arXiv:2504.20039 ' url: https://arxiv.org/abs/2504.20039\n\t\t\t\t[3924] link 'pdf' url: https://arxiv.org/pdf/2504.20039\n\t\t\t\t[3927] link 'html' url: https://arxiv.org/html/2504.20039v1\n\t\t\t\t[3929] StaticText ', '\n\t\t\t\t[3930] link 'other' url: https://arxiv.org/format/2504.20039\n\t\t\t[3934] definition ''\n\t\t\t\t[3941] StaticText 'AutoJudge: Judge Decoding Without Manual Annotation'\n\t\t\t\t[3944] link 'Roman Garipov' url: https://arxiv.org/search/cs?searchtype=author&query=Garipov,+R\n\t\t\t\t[3946] StaticText ', '\n\t\t\t\t[3947] link 'Fedor Velikonivtsev' url: https://arxiv.org/search/cs?searchtype=author&query=Velikonivtsev,+F\n\t\t\t\t[3950] link 'Ruslan Svirschevski' url: https://arxiv.org/search/cs?searchtype=author&query=Svirschevski,+R\n\t\t\t\t[3953] link 'Vage Egiazarian' url: https://arxiv.org/search/cs?searchtype=author&query=Egiazarian,+V\n\t\t\t\t[3955] StaticText ', '\n\t\t\t\t[3956] link 'Max Ryabinin' url: https://arxiv.org/search/cs?searchtype=author&query=Ryabinin,+M\n\t\t\t\t[3961] StaticText 'Comments:'\n\t\t\t\t[3962] StaticText ' Preprint, Work in progress'\n\t\t\t\t[3966] StaticText 'Subjects:'\n\t\t\t\t[3969] StaticText 'Computation and Language (cs.CL)'\n\t\t\t\t[3970] StaticText '; Machine Learning (cs.LG)'\n\t\t\t[3570] term '[2] arXiv:2504.20022 [ pdf , html , other ]'\n\t\t\t\t[3978] link 'arXiv:2504.20022 ' url: https://arxiv.org/abs/2504.20022\n\t\t\t\t[3981] link 'pdf' url: https://arxiv.org/pdf/2504.20022\n\t\t\t\t[3984] link 'html' url: https://arxiv.org/html/2504.20022v1\n\t\t\t\t[3986] StaticText ', '\n\t\t\t\t[3987] link 'other' url: https://arxiv.org/format/2504.20022\n\t\t\t[3991] definition ''\n\t\t\t\t[3998] StaticText 'Better To Ask in English? Evaluating Factual Accuracy of Multilingual LLMs in English and Low-Resource Languages'\n\t\t\t\t[4001] link 'Pritika Rohera' url: https://arxiv.org/search/cs?searchtype=author&query=Rohera,+P\n\t\t\t\t[4003] StaticText ', '\n\t\t\t\t[4004] link 'Chaitrali Ginimav' url: https://arxiv.org/search/cs?searchtype=author&query=Ginimav,+C\n\t\t\t\t[4007] link 'Gayatri Sawant' url: https://arxiv.org/search/cs?searchtype=author&query=Sawant,+G\n\t\t\t\t[4010] link 'Raviraj Joshi' url: https://arxiv.org/search/cs?searchtype=author&query=Joshi,+R\n\t\t\t\t[4015] StaticText 'Subjects:'\n\t\t\t\t[4018] StaticText 'Computation and Language (cs.CL)'\n\t\t\t\t[4019] StaticText '; Machine Learning (cs.LG)'\n\t\t\t[4023] term '[3] arXiv:2504.20013 [ pdf , html , other ]'\n\t\t\t\t[4028] link 'arXiv:2504.20013 ' url: https://arxiv.org/abs/2504.20013\n\t\t\t\t[4031] link 'pdf' url: https://arxiv.org/pdf/2504.20013\n\t\t\t\t[4034] link 'html' url: https://arxiv.org/html/2504.20013v1\n\t\t\t\t[4036] StaticText ', '\n\t\t\t\t[4037] link 'other' url: https://arxiv.org/format/2504.20013\n\t\t\t[4041] definition ''\n\t\t\t\t[4048] StaticText 'LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation'\n\t\t\t\t[4051] link 'Beizhe Hu' url: https://arxiv.org/search/cs?searchtype=author&query=Hu,+B\n\t\t\t\t[4053] StaticText ', '\n\t\t\t\t[4054] link 'Qiang Sheng' url: https://arxiv.org/search/cs?searchtype=author&query=Sheng,+Q\n\t\t\t\t[4057] link 'Juan Cao' url: https://arxiv.org/search/cs?searchtype=author&query=Cao,+J\n\t\t\t\t[4060] link 'Yang Li' url: https://arxiv.org/search/cs?searchtype=author&query=Li,+Y\n\t\t\t\t[4062] StaticText ', '\n\t\t\t\t[4063] link 'Danding Wang' url: https://arxiv.org/search/cs?searchtype=author&query=Wang,+D\n\t\t\t\t[4068] StaticText 'Comments:'\n\t\t\t\t[4069] StaticText ' ACM SIGIR 2025 Full Paper'\n\t\t\t\t[4073] StaticText 'Subjects:'\n\t\t\t\t[4076] StaticText 'Computation and Language (cs.CL)'\n\t\t\t\t[4077] StaticText '; Computers and Society (cs.CY); Information Retrieval (cs.IR)'\n\t\t\t[4081] term '[4] arXiv:2504.20000 [ pdf , html , other ]'\n\t\t\t\t[4086] link 'arXiv:2504.20000 ' url: https://arxiv.org/abs/2504.20000\n\t\t\t\t[4089] link 'pdf' url: https://arxiv.org/pdf/2504.20000\n\t\t\t\t[4092] link 'html' url: https://arxiv.org/html/2504.20000v1\n\t\t\t\t[4094] StaticText ', '\n\t\t\t\t[4095] link 'other' url: https://arxiv.org/format/2504.20000\n\t\t\t[4099] definition ''\n\t\t\t\t[4106] StaticText 'Knowledge Distillation of Domain-adapted LLMs for Question-Answering in Telecom'\n\t\t\t\t[4109] link 'Rishika Sen' url: https://arxiv.org/search/cs?searchtype=author&query=Sen,+R\n\t\t\t\t[4111] StaticText ', '\n\t\t\t\t[4112] link 'Sujoy Roychowdhury' url: https://arxiv.org/search/cs?searchtype=author&query=Roychowdhury,+S\n\t\t\t\t[4115] link 'Sumit Soman' url: https://arxiv.org/search/cs?searchtype=author&query=Soman,+S\n\t\t\t\t[4118] link 'H. G. Ranjani' url: https://arxiv.org/search/cs?searchtype=author&query=Ranjani,+H+G\n\t\t\t\t[4120] StaticText ', '\n\t\t\t\t[4121] link 'Srikhetra Mohanty' url: https://arxiv.org/search/cs?searchtype=author&query=Mohanty,+S\n\t\t\t\t[4126] StaticText 'Comments:'\n\t\t\t\t[4127] StaticText ' 10 pages, 4 figures, 3 tables'\n\t\t\t\t[4131] StaticText 'Subjects:'\n\t\t\t\t[4134] StaticText 'Computation and Language (cs.CL)'\n\t\t\t\t[4135] StaticText '; Information Retrieval (cs.IR); Machine Learning (cs.LG)'\n\t\t\t[4139] term '[5] arXiv:2504.19982 [ pdf , html , other ]'\n\t\t\t\t[4144] link 'arXiv:2504.19982 ' url: https://arxiv.org/abs/2504.19982\n\t\t\t\t[4147] link 'pdf' url: https://arxiv.org/pdf/2504.19982\n\t\t\t\t[4150] link 'html' url: https://arxiv.org/html/2504.19982v1\n\t\t\t\t[4152] StaticText ', '\n\t\t\t\t[4153] link 'other' url: https://arxiv.org/format/2504.19982\n\t\t\t[4157] definition ''\n\t\t\t\t[4164] StaticText 'TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons'\n\t\t\t\t[4167] link 'Emre Can Acikgoz' url: https://arxiv.org/search/cs?searchtype=author&query=Acikgoz,+E+C\n\t\t\t\t[4169] StaticText ', '\n\t\t\t\t[4170] link 'Carl Guo' url: https://arxiv.org/search/cs?searchtype=author&query=Guo,+C\n\t\t\t\t[4173] link 'Suvodip Dey' url: https://arxiv.org/search/cs?searchtype=author&query=Dey,+S\n\t\t\t\t[4176] link 'Akul Datta' url: https://arxiv.org/search/cs?searchtype=author&query=Datta,+A\n\t\t\t\t[4178] StaticText ', '\n\t\t\t\t[4179] link 'Takyoung Kim' url: https://arxiv.org/search/cs?searchtype=author&query=Kim,+T\n\t\t\t\t[4182] link 'Gokhan Tur' url: https://arxiv.org/search/cs?searchtype=author&query=Tur,+G\n\t\t\t\t[4185] link 'Dilek Hakkani-Tür' url: https://arxiv.org/search/cs?searchtype=author&query=Hakkani-T%C3%BCr,+D\n\t\t\t\t[4190] StaticText 'Subjects:'\n\t\t\t\t[4193] StaticText 'Computation and Language (cs.CL)'\n\t\t\t\t[4194] StaticText '; Artificial Intelligence (cs.AI)'\n\t\t\t[4198] term '[6] arXiv:2504.19940 [ pdf , html , other ]'\n\t\t\t\t[4203] link 'arXiv:2504.19940 ' url: https://arxiv.org/abs/2504.19940\n\t\t\t\t[4206] link 'pdf' url: https://arxiv.org/pdf/2504.19940\n\t\t\t\t[4209] link 'html' url: https://arxiv.org/html/2504.19940v1\n\t\t\t\t[4211] StaticText ', '\n\t\t\t\t[4212] link 'other' url: https://arxiv.org/format/2504.19940\n\t\t\t[4216] definition ''\n\t\t\t\t[4223] StaticText 'Assessing the Potential of Generative Agents in Crowdsourced Fact-Checking'\n\t\t\t\t[4226] link 'Luigia Costabile' url: https://arxiv.org/search/cs?searchtype=author&query=Costabile,+L\n\t\t\t\t[4228] StaticText ', '\n\t\t\t\t[4229] link 'Gian Marco Orlando' url: https://arxiv.org/search/cs?searchtype=author&query=Orlando,+G+M\n\t\t\t\t[4232] link 'Valerio La Gatta' url: https://arxiv.org/search/cs?searchtype=author&query=La+Gatta,+V\n\t\t\t\t[4235] link 'Vincenzo Moscato' url: https://arxiv.org/search/cs?searchtype=author&query=Moscato,+V\n\t\t\t\t[4240] StaticText 'Subjects:'\n\t\t\t\t[4243] StaticText 'Computation and Language (cs.CL)'\n\t\t\t\t[4244] StaticText '; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)'\n\t\t\t[4248] term '[7] arXiv:2504.19898 [ pdf , html , other ]'\n\t\t\t\t[4253] link 'arXiv:2504.19898 ' url: https://arxiv.org/abs/2504.19898\n\t\t\t\t[4256] link 'pdf' url: https://arxiv.org/pdf/2504.19898\n\t\t\t\t[4259] link 'html' url: https://arxiv.org/html/2504.19898v1\n\t\t\t\t[4261] StaticText ', '\n\t\t\t\t[4262] link 'other' url: https://arxiv.org/format/2504.19898\n\t\t\t[4266] definition ''\n\t\t\t\t[4273] StaticText 'GenCLS++: Pushing the Boundaries of Generative Classification in LLMs Through Comprehensive SFT and RL Studies Across Diverse Datasets'\n\t\t\t\t[4276] link 'Mingqian He' url: https://arxiv.org/search/cs?searchtype=author&query=He,+M\n\t\t\t\t[4278] StaticText ', '\n\t\t\t\t[4279] link 'Fei Zhao' url: https://arxiv.org/search/cs?searchtype=author&query=Zhao,+F\n\t\t\t\t[4282] link 'Chonggang Lu' url: https://arxiv.org/search/cs?searchtype=author&query=Lu,+C\n\t\t\t\t[4285] link 'Ziyan Liu' url: https://arxiv.org/search/cs?searchtype=author&query=Liu,+Z\n\t\t\t\t[4287] StaticText ', '\n\t\t\t\t[4288] link 'Yue Wang' url: https://arxiv.org/search/cs?searchtype=author&query=Wang,+Y\n\t\t\t\t[4291] link 'Haofu Qian' url: https://arxiv.org/search/cs?searchtype=author&query=Qian,+H\n\t\t\t\t[4296] StaticText 'Subjects:'\n\t\t\t\t[4299] StaticText 'Computation and Language (cs.CL)'\n\t\t\t[4304] term '[8] arXiv:2504.19867 [ pdf , html , other ]'\n\t\t\t\t[4309] link 'arXiv:2504.19867 ' url: https://arxiv.org/abs/2504.19867\n\t\t\t\t[4312] link 'pdf' url: https://arxiv.org/pdf/2504.19867\n\t\t\t\t[4315] link 'html' url: https://arxiv.org/html/2504.19867v1\n\t\t\t\t[4317] StaticText ', '\n\t\t\t\t[4318] link 'other' url: https://arxiv.org/format/2504.19867\n\t\t\t[4322] definition ''\n\t\t\t\t[4329] StaticText 'semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated Computation and Unified Storage'\n\t\t\t\t[4332] link 'Ke Hong' url: https://arxiv.org/search/cs?searchtype=author&query=Hong,+K\n\t\t\t\t[4334] StaticText ', '\n\t\t\t\t[4335] link 'Lufang Chen' url: https://arxiv.org/search/cs?searchtype=author&query=Chen,+L\n\t\t\t\t[4338] link 'Zhong Wang' url: https://arxiv.org/search/cs?searchtype=author&query=Wang,+Z\n\t\t\t\t[4341] link 'Xiuhong Li' url: https://arxiv.org/search/cs?searchtype=author&query=Li,+X\n\t\t\t\t[4343] StaticText ', '\n\t\t\t\t[4344] link 'Qiuli Mao' url: https://arxiv.org/search/cs?searchtype=author&query=Mao,+Q\n\t\t\t\t[4347] link 'Jianping Ma' url: https://arxiv.org/search/cs?searchtype=author&query=Ma,+J\n\t\t\t\t[4350] link 'Chao Xiong' url: https://arxiv.org/search/cs?searchtype=author&query=Xiong,+C\n\t\t\t\t[4352] StaticText ', '\n\t\t\t\t[4353] link 'Guanyu Wu' url: https://arxiv.org/search/cs?searchtype=author&query=Wu,+G\n\t\t\t\t[4356] link 'Buhe Han' url: https://arxiv.org/search/cs?searchtype=author&query=Han,+B\n\t\t\t\t[4359] link 'Guohao Dai' url: https://arxiv.org/search/cs?searchtype=author&query=Dai,+G\n\t\t\t\t[4361] StaticText ', '\n\t\t\t\t[4362] link 'Yun Liang' url: https://arxiv.org/search/cs?searchtype=author&query=Liang,+Y\n\t\t\t\t[4365] link 'Yu Wang' url: https://arxiv.org/search/cs?searchtype=author&query=Wang,+Y\n\t\t\t\t[4370] StaticText 'Comments:'\n\t\t\t\t[4371] StaticText ' 18 pages, 16 figures'\n\t\t\t\t[4375] StaticText 'Subjects:'\n\t\t\t\t[4378] StaticText 'Computation and Language (cs.CL)'\n\t\t\t\t[4379] StaticText '; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)'\n\t\t\t[4383] term '[9] arXiv:2504.19856 [ pdf , html , other ]'\n\t\t\t\t[4388] link 'arXiv:2504.19856 ' url: https://arxiv.org/abs/2504.19856\n\t\t\t\t[4391] link 'pdf' url: https://arxiv.org/pdf/2504.19856\n\t\t\t\t[4394] link 'html' url: https://arxiv.org/html/2504.19856v1\n\t\t\t\t[4396] StaticText ', '\n\t\t\t\t[4397] link 'other' url: https://arxiv.org/format/2504.19856\n\t\t\t[4401] definition ''\n\t\t\t\t[4408] StaticText 'Efficient Domain-adaptive Continual Pretraining for the Process Industry in the German Language'\n\t\t\t\t[4411] link 'Anastasia Zhukova' url: https://arxiv.org/search/cs?searchtype=author&query=Zhukova,+A\n\t\t\t\t[4413] StaticText ', '\n\t\t\t\t[4414] link 'Christian E. Matt' url: https://arxiv.org/search/cs?searchtype=author&query=Matt,+C+E\n\t\t\t\t[4417] link 'Terry Ruas' url: https://arxiv.org/search/cs?searchtype=author&query=Ruas,+T\n\t\t\t\t[4420] link 'Bela Gipp' url: https://arxiv.org/search/cs?searchtype=author&query=Gipp,+B\n\t\t\t\t[4425] StaticText 'Subjects:'\n\t\t\t\t[4428] StaticText 'Computation and Language (cs.CL)'\n\t\t\t[4433] term '[10] arXiv:2504.19850 [ pdf , html , other ]'\n\t\t\t\t[4438] link 'arXiv:2504.19850 ' url: https://arxiv.org/abs/2504.19850\n\t\t\t\t[4441] link 'pdf' url: https://arxiv.org/pdf/2504.19850\n\t\t\t\t[4444] link 'html' url: https://arxiv.org/html/2504.19850v1\n\t\t\t\t[4446] StaticText ', '\n\t\t\t\t[4447] link 'other' url: https://arxiv.org/format/2504.19850\n\t\t\t[4451] definition ''\n\t\t\t\t[4458] StaticText 'To MT or not to MT: An eye-tracking study on the reception by Dutch readers of different translation and creativity levels'\n\t\t\t\t[4461] link 'Kyo Gerrits' url: https://arxiv.org/search/cs?searchtype=author&query=Gerrits,+K\n\t\t\t\t[4463] StaticText ', '\n\t\t\t\t[4464] link 'Ana Guerberof-Arenas' url: https://arxiv.org/search/cs?searchtype=author&query=Guerberof-Arenas,+A\n\t\t\t\t[4469] StaticText 'Comments:'\n\t\t\t\t[4470] StaticText ' This paper has been accepted to the MT Summit 2025 to be held in Geneva on June 23-27 2025'\n\t\t\t\t[4474] StaticText 'Subjects:'\n\t\t\t\t[4477] StaticText 'Computation and Language (cs.CL)'\n\t\t\t[4482] term '[11] arXiv:2504.19811 [ pdf , html , other ]'\n\t\t\t\t[4487] link 'arXiv:2504.19811 ' url: https://arxiv.org/abs/2504.19811\n\t\t\t\t[4490] link 'pdf' url: https://arxiv.org/pdf/2504.19811\n\t\t\t\t[4493] link 'html' url: https://arxiv.org/html/2504.19811v1\n\t\t\t\t[4495] StaticText ', '\n\t\t\t\t[4496] link 'other' url: https://arxiv.org/format/2504.19811\n\t\t\t[4500] definition ''\n\t\t\t\t[4507] StaticText 'Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance'\n\t\t\t\t[4510] link 'Takuya Tamura' url: https://arxiv.org/search/cs?searchtype=author&query=Tamura,+T\n\t\t\t\t[4512] StaticText ', '\n\t\t\t\t[4513] link 'Taro Yano' url: https://arxiv.org/search/cs?searchtype=author&query=Yano,+T\n\t\t\t\t[4516] link 'Masafumi Enomoto' url: https://arxiv.org/search/cs?searchtype=author&query=Enomoto,+M\n\t\t\t\t[4519] link 'Masafumi Oyamada' url: https://arxiv.org/search/cs?searchtype=author&query=Oyamada,+M\n\t\t\t\t[4524] StaticText 'Subjects:'\n\t\t\t\t[4527] StaticText 'Computation and Language (cs.CL)'\n\t\t\t[4532] term '[12] arXiv:2504.19759 [ pdf , html , other ]'\n\t\t\t\t[4537] link 'arXiv:2504.19759 ' url: https://arxiv.org/abs/2504.19759\n\t\t\t\t[4540] link 'pdf' url: https://arxiv.org/pdf/2504.19759\n\t\t\t\t[4543] link 'html' url: https://arxiv.org/html/2504.19759v1\n\t\t\t\t[4545] StaticText ', '\n\t\t\t\t[4546] link 'other' url: https://arxiv.org/format/2504.19759\n\t\t\t[4550] definition ''\n\t\t\t\t[4557] StaticText 'Moral Reasoning Across Languages: The Critical Role of Low-Resource Languages in LLMs'\n\t\t\t\t[4560] link 'Huichi Zhou' url: https://arxiv.org/search/cs?searchtype=author&query=Zhou,+H\n\t\t\t\t[4562] StaticText ', '\n\t\t\t\t[4563] link 'Zehao Xu' url: https://arxiv.org/search/cs?searchtype=author&query=Xu,+Z\n\t\t\t\t[4566] link 'Munan Zhao' url: https://arxiv.org/search/cs?searchtype=author&query=Zhao,+M\n\t\t\t\t[4569] link 'Kaihong Li' url: https://arxiv.org/search/cs?searchtype=author&query=Li,+K\n\t\t\t\t[4571] StaticText ', '\n\t\t\t\t[4572] link 'Yiqiang Li' url: https://arxiv.org/search/cs?searchtype=author&query=Li,+Y\n\t\t\t\t[4575] link 'Hongtao Wang' url: https://arxiv.org/search/cs?searchtype=author&query=Wang,+H"
  },
  {
    "role": "assistant",
    "content": "Thought: Need to open the first recent cs.CL paper's detail page to view abstract.\nAction: Click 3921"
  },
  {
    "role": "user",
    "content": "Observation: please analyze the accessibility tree and give the Thought and Action.\n[6942] RootWebArea '[2504.20039] AutoJudge: Judge Decoding Without Manual Annotation' focused: True url: https://arxiv.org/abs/2504.20039\n\t[7089] StaticText 'Skip to main content'\n\t[7097] link 'Cornell University' url: https://www.cornell.edu/\n\t\t[6946] image 'Cornell University' url: https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\n\t[7104] StaticText 'We gratefully acknowledge support from the Simons Foundation, '\n\t[7105] link 'member institutions' url: https://info.arxiv.org/about/ourmembers.html\n\t[7107] StaticText ', and all contributors.'\n\t[7109] link 'Donate' url: https://info.arxiv.org/about/donate.html\n\t[7120] link 'arxiv logo' url: https://arxiv.org/\n\t\t[6947] image 'arxiv logo' url: https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg\n\t[7123] StaticText '>'\n\t[7125] link 'cs' url: https://arxiv.org/list/cs/recent\n\t[7130] StaticText 'arXiv:2504.20039'\n\t[6951] textbox 'Search term or terms' required: False\n\t[7141] link 'Help' url: https://info.arxiv.org/help\n\t[7143] StaticText ' | '\n\t[7144] link 'Advanced Search' url: https://arxiv.org/search/advanced\n\t[6952] combobox 'Field to search' hasPopup: menu expanded: False\n\t[7204] button 'Search'\n\t[7292] main ''\n\t\t[7303] heading 'Computer Science > Computation and Language'\n\t\t[7320] StaticText '[Submitted on 28 Apr 2025]'\n\t\t[7322] heading 'AutoJudge: Judge Decoding Without Manual Annotation'\n\t\t[6949] link 'Roman Garipov' url: https://arxiv.org/search/cs?searchtype=author&query=Garipov,+R\n\t\t[7331] StaticText ', '\n\t\t[7332] link 'Fedor Velikonivtsev' url: https://arxiv.org/search/cs?searchtype=author&query=Velikonivtsev,+F\n\t\t[7335] link 'Ruslan Svirschevski' url: https://arxiv.org/search/cs?searchtype=author&query=Svirschevski,+R\n\t\t[7338] link 'Vage Egiazarian' url: https://arxiv.org/search/cs?searchtype=author&query=Egiazarian,+V\n\t\t[7340] StaticText ', '\n\t\t[7341] link 'Max Ryabinin' url: https://arxiv.org/search/cs?searchtype=author&query=Ryabinin,+M\n\t\t[6977] blockquote ''\n\t\t\t[7356] StaticText 'We introduce AutoJudge, a framework that accelerates large language model (LLM) inference with task-specific lossy speculative decoding. Instead of matching the original model output distribution token-by-token, we identify which of the generated tokens affect the downstream quality of the generated response, relaxing the guarantee so that the \"unimportant\" tokens can be generated faster. Our approach relies on a semi-greedy search algorithm to test which of the mismatches between target and draft model should be corrected to preserve quality, and which ones may be skipped. We then train a lightweight classifier based on existing LLM embeddings to predict, at inference time, which mismatching tokens can be safely accepted without compromising the final answer quality. We test our approach with Llama 3.2 1B (draft) and Llama 3.1 8B (target) models on zero-shot GSM8K reasoning, where it achieves up to 1.5x more accepted tokens per verification cycle with under 1% degradation in answer accuracy compared to standard speculative decoding and over 2x with small loss in accuracy. When applied to the LiveCodeBench benchmark, our approach automatically detects other, programming-specific important tokens and shows similar speedups, demonstrating its ability to generalize across tasks.'\n\t\t[7362] table 'Additional metadata'\n\t\t\t[7365] row ''\n\t\t\t\t[7367] cell 'Comments:'\n\t\t\t\t[7370] cell 'Preprint, Work in progress'\n\t\t\t[7374] row ''\n\t\t\t\t[7376] cell 'Subjects:'\n\t\t\t\t[7379] cell 'Computation and Language (cs.CL); Machine Learning (cs.LG)'\n\t\t\t[7385] row ''\n\t\t\t\t[7387] cell 'Cite as:'\n\t\t\t\t[7390] cell 'arXiv:2504.20039 [cs.CL]'\n\t\t\t\t\t[7392] link 'arXiv:2504.20039' url: https://arxiv.org/abs/2504.20039\n\t\t\t[7397] row ''\n\t\t\t\t[7399] cell '\\xa0'\n\t\t\t\t[7402] cell '(or arXiv:2504.20039v1 [cs.CL] for this version)'\n\t\t\t\t\t[7406] link 'arXiv:2504.20039v1' url: https://arxiv.org/abs/2504.20039v1\n\t\t\t[7412] row ''\n\t\t\t\t[7414] cell '\\xa0'\n\t\t\t\t[7417] cell 'https://doi.org/10.48550/arXiv.2504.20039 Focus to learn more'\n\t\t\t\t\t[7419] link 'https://doi.org/10.48550/arXiv.2504.20039' url: https://doi.org/10.48550/arXiv.2504.20039\n\t\t\t\t\t[7423] button 'Focus to learn more' describedby: more-info-desc-1\n\t\t[7447] heading 'Submission history'\n\t\t[7449] StaticText 'From: Roman Garipov ['\n\t\t[7450] link 'view email' url: https://arxiv.org/show-email/af0ff4ec/2504.20039\n\t\t[7456] StaticText '[v1]'\n\t\t[7457] StaticText ' Mon, 28 Apr 2025 17:59:28 UTC (3,092 KB)'\n\t\t[7473] heading 'Access Paper:'\n\t\t[7481] link 'View PDF' describedby: download-button-info url: https://arxiv.org/pdf/2504.20039 keyshortcuts: Alt+f\n\t\t[7484] link 'HTML (experimental)' url: https://arxiv.org/html/2504.20039v1\n\t\t[7487] link 'TeX Source' url: https://arxiv.org/src/2504.20039\n\t\t[7490] link 'Other Formats' url: https://arxiv.org/format/2504.20039\n\t\t[7494] link 'view license' url: http://creativecommons.org/licenses/by-nc-sa/4.0/\n\t\t[7505] StaticText 'Current browse context:'\n\t\t[7507] StaticText 'cs.CL'\n\t\t[7513] link '<\\xa0prev' url: https://arxiv.org/prevnext?id=2504.20039&function=prev&context=cs.CL keyshortcuts: Alt+p\n\t\t[7518] StaticText '\\xa0 | \\xa0'\n\t\t[7522] link 'next\\xa0>' url: https://arxiv.org/prevnext?id=2504.20039&function=next&context=cs.CL keyshortcuts: Alt+n\n\t\t[7529] link 'new' url: https://arxiv.org/list/cs.CL/new\n\t\t[7535] link 'recent' url: https://arxiv.org/list/cs.CL/recent\n\t\t[7539] StaticText '| '\n\t\t[7540] link '2025-04' url: https://arxiv.org/list/cs.CL/2025-04\n\t\t[7544] StaticText 'Change to browse by:'\n\t\t[7547] link 'cs' url: https://arxiv.org/abs/2504.20039?context=cs\n\t\t[6948] link 'cs.LG' url: https://arxiv.org/abs/2504.20039?context=cs.LG\n\t\t[7559] heading 'References & Citations'\n\t\t[7565] link 'NASA ADS' url: https://ui.adsabs.harvard.edu/abs/arXiv:2504.20039\n\t\t[7568] link 'Google Scholar' url: https://scholar.google.com/scholar_lookup?arxiv_id=2504.20039\n\t\t[7572] link 'Semantic Scholar' url: https://api.semanticscholar.org/arXiv:2504.20039\n\t\t[7585] StaticText 'Export BibTeX Citation'\n\t\t[7621] heading 'Bookmark'\n\t\t[7623] link 'BibSonomy logo' url: http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2504.20039&description=AutoJudge:%20Judge%20Decoding%20Without%20Manual%20Annotation\n\t\t\t[6944] image 'BibSonomy logo' url: https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png\n\t\t[7627] link 'Reddit logo' url: https://reddit.com/submit?url=https://arxiv.org/abs/2504.20039&title=AutoJudge:%20Judge%20Decoding%20Without%20Manual%20Annotation\n\t\t\t[6945] image 'Reddit logo' url: https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png\n\t\t[7642] StaticText 'Bibliographic Tools'\n\t\t[7646] heading 'Bibliographic and Citation Tools'\n\t\t[7662] StaticText 'Bibliographic Explorer Toggle'\n\t\t[7671] emphasis ''\n\t\t\t[7672] StaticText '('\n\t\t\t[7673] link 'What is the Explorer?' url: https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer\n\t\t\t[7675] StaticText ')'\n\t\t[7690] StaticText 'Connected Papers Toggle'\n\t\t[7699] emphasis ''\n\t\t\t[7700] StaticText '('\n\t\t\t[7701] link 'What is Connected Papers?' url: https://www.connectedpapers.com/about\n\t\t\t[7703] StaticText ')'\n\t\t[7717] StaticText 'Litmaps Toggle'\n\t\t[7726] emphasis ''\n\t\t\t[7727] StaticText '('\n\t\t\t[7728] link 'What is Litmaps?' url: https://www.litmaps.co/\n\t\t\t[7730] StaticText ')'\n\t\t[7745] StaticText 'scite.ai Toggle'\n\t\t[7752] StaticText 'scite Smart Citations'\n\t\t[7754] emphasis ''\n\t\t\t[7755] StaticText '('\n\t\t\t[7756] link 'What are Smart Citations?' url: https://www.scite.ai/\n\t\t\t[7758] StaticText ')'\n\t\t[7774] StaticText 'Code, Data, Media'\n\t\t[7992] StaticText 'Demos'\n\t\t[8092] StaticText 'Related Papers'\n\t\t[8201] StaticText 'About arXivLabs'\n\t\t[8247] link 'Which authors of this paper are endorsers?' url: https://arxiv.org/auth/show-endorsers/2504.20039\n\t\t[8249] StaticText ' | '\n\t\t[8250] link 'Disable MathJax' url: javascript:setMathjaxCookie()\n\t\t[8252] StaticText ' ('\n\t\t[8253] link 'What is MathJax?' url: https://info.arxiv.org/help/mathjax.html\n\t[8265] contentinfo ''\n\t\t[8267] navigation 'Secondary'\n\t\t\t[8280] link 'About' url: https://info.arxiv.org/about\n\t\t\t[8284] link 'Help' url: https://info.arxiv.org/help\n\t\t\t[8302] link 'Contact' url: https://info.arxiv.org/help/contact.html\n\t\t\t[8315] link 'Subscribe' url: https://info.arxiv.org/help/subscribe\n\t\t\t[8336] link 'Copyright' url: https://info.arxiv.org/help/license/index.html\n\t\t\t[8340] link 'Privacy Policy' url: https://info.arxiv.org/help/policies/privacy_policy.html\n\t\t\t[8350] link 'Web Accessibility Assistance' url: https://info.arxiv.org/help/web_accessibility.html\n\t\t\t[8357] link 'arXiv Operational Status ' url: https://status.arxiv.org/\n\t\t\t[8362] StaticText 'Get status notifications via '\n\t\t\t[8363] link 'email' url: https://subscribe.sorryapp.com/24846f03/email/new\n\t\t\t[8367] StaticText ' or '\n\t\t\t[8368] link 'slack' url: https://subscribe.sorryapp.com/24846f03/slack/new"
  },
  {
    "role": "assistant",
    "content": "ANSWER; AutoJudge: Judge Decoding Without Manual Annotation (arXiv:2504.20039, cs.CL, submitted 28 Apr 2025)\n\nAbstract:\nWe introduce AutoJudge, a framework that accelerates large language model (LLM) inference with task‑specific lossy speculative decoding. Instead of matching the original model output distribution token‑by‑token, we identify which of the generated tokens affect the downstream quality of the generated response, relaxing the guarantee so that the “unimportant” tokens can be generated faster. Our approach relies on a semi‑greedy search algorithm to test which of the mismatches between target and draft model should be corrected to preserve quality, and which ones may be skipped. We then train a lightweight classifier based on existing LLM embeddings to predict, at inference time, which mismatching tokens can be safely accepted without compromising the final answer quality. We test our approach with Llama 3.2 1B (draft) and Llama 3.1 8B (target) models on zero‑shot GSM8K reasoning, where it achieves up to 1.5× more accepted tokens per verification cycle with under 1 % degradation in answer accuracy compared to standard speculative decoding and over 2× with small loss in accuracy. When applied to the LiveCodeBench benchmark, our approach automatically detects other, programming‑specific important tokens and shows similar speedups, demonstrating its ability to generalize across tasks."
  },
  {
    "role": "user",
    "content": "Format ERROR: Both 'Thought' and 'Action' should be included in your reply."
  },
  {
    "role": "assistant",
    "content": "Thought: Abstract for the most recent cs.CL paper has been retrieved.\nAction: ANSWER; AutoJudge: Judge Decoding Without Manual Annotation (arXiv:2504.20039, cs.CL, submitted 28 Apr 2025)\n\nAbstract:\nWe introduce AutoJudge, a framework that accelerates large language model (LLM) inference with task‑specific lossy speculative decoding. Instead of matching the original model output distribution token‑by‑token, we identify which of the generated tokens affect the downstream quality of the generated response, relaxing the guarantee so that the “unimportant” tokens can be generated faster. Our approach relies on a semi‑greedy search algorithm to test which of the mismatches between target and draft model should be corrected to preserve quality, and which ones may be skipped. We then train a lightweight classifier based on existing LLM embeddings to predict, at inference time, which mismatching tokens can be safely accepted without compromising the final answer quality. We test our approach with Llama 3.2 1B (draft) and Llama 3.1 8B (target) models on zero‑shot GSM8K reasoning, where it achieves up to 1.5× more accepted tokens per verification cycle with under 1 % degradation in answer accuracy compared to standard speculative decoding and over 2× with small loss in accuracy. When applied to the LiveCodeBench benchmark, our approach automatically detects other, programming‑specific important tokens and shows similar speedups, demonstrating its ability to generalize across tasks."
  }
]