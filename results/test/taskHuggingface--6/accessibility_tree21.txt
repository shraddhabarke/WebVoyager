[1781] RootWebArea 'sentence-transformers/all-MiniLM-L6-v2 ¬∑ Hugging Face' focused: True url: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
	[2096] main ''
		[2616] button ''
		[2776] code ''
			[2817] StaticText '()\n    '
			[2819] StaticText 'return'
			[2820] StaticText ' torch.'
			[2822] StaticText 'sum'
			[2823] StaticText '(token_embeddings * input_mask_expanded, '
			[2825] StaticText '1'
			[2826] StaticText ') / torch.clamp(input_mask_expanded.'
			[2828] StaticText 'sum'
			[2832] StaticText '), '
			[2834] StaticText 'min'
			[2835] StaticText '='
			[2837] StaticText '1e-9'
			[2838] StaticText ')\n\n\n'
			[2840] StaticText '# Sentences we want sentence embeddings for'
			[2841] StaticText '\nsentences = ['
			[2844] StaticText ', '
			[2847] StaticText ']\n\n'
			[2849] StaticText '# Load model from HuggingFace Hub'
			[2850] StaticText '\ntokenizer = AutoTokenizer.from_pretrained('
			[2853] StaticText ')\nmodel = AutoModel.from_pretrained('
			[2856] StaticText ')\n\n'
			[2858] StaticText '# Tokenize sentences'
			[2859] StaticText '\nencoded_input = tokenizer(sentences, padding='
			[2861] StaticText 'True'
			[2862] StaticText ', truncation='
			[2865] StaticText ', return_tensors='
			[2868] StaticText ')\n\n'
			[2870] StaticText '# Compute token embeddings'
			[2873] StaticText 'with'
			[2874] StaticText ' torch.no_grad():\n    model_output = model(**encoded_input)\n\n'
			[2876] StaticText '# Perform pooling'
			[2877] StaticText '\nsentence_embeddings = mean_pooling(model_output, encoded_input['
			[2880] StaticText '])\n\n'
			[2882] StaticText '# Normalize embeddings'
			[2883] StaticText '\nsentence_embeddings = F.normalize(sentence_embeddings, p='
			[2886] StaticText ', dim='
			[2888] StaticText '1'
			[2889] StaticText ')\n\n'
			[2891] StaticText 'print'
			[2892] StaticText '('
			[2894] StaticText '"Sentence embeddings:"'
			[2895] StaticText ')\n'
			[2897] StaticText 'print'
			[2898] StaticText '(sentence_embeddings)\n'
		[2905] separator '' orientation: horizontal
		[2907] heading 'Background'
			[2909] link '' url: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2#background
		[2921] StaticText 'The project aims to train sentence embedding models on very large sentence level datasets using a self-supervised contrastive learning objective. We used the pretrained '
		[2922] link 'nreimers/MiniLM-L6-H384-uncased' url: https://huggingface.co/nreimers/MiniLM-L6-H384-uncased
			[2923] code ''
		[2927] StaticText ' model and fine-tuned in on a 1B sentence pairs dataset. We use a contrastive learning objective: given a sentence from the pair, the model should predict which out of a set of randomly sampled other sentences, was actually paired with it in our dataset.'
		[2930] StaticText 'We developed this model during the '
		[2931] link 'Community week using JAX/Flax for NLP & CV' url: https://discuss.huggingface.co/t/open-to-the-community-community-week-using-jax-flax-for-nlp-cv/7104
		[2933] StaticText ', organized by Hugging Face. We developed this model as part of the project: '
		[2934] link 'Train the Best Sentence Embedding Model Ever with 1B Training Pairs' url: https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354
		[2936] StaticText '. We benefited from efficient hardware infrastructure to run the project: 7 TPUs v3-8, as well as intervention from Googles Flax, JAX, and Cloud team member about efficient deep learning frameworks.'
		[2938] heading 'Intended uses'
			[2940] link '' url: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2#intended-uses
		[2952] StaticText 'Our model is intended to be used as a sentence and short paragraph encoder. Given an input text, it outputs a vector which captures the semantic information. The sentence vector may be used for information retrieval, clustering or sentence similarity tasks.'
		[3983] heading 'Spaces using sentence-transformers/all-MiniLM-L6-v2 100'
		[3999] link 'ü•á mteb/leaderboard' url: https://huggingface.co/spaces/mteb/leaderboard
		[4006] link 'üåç cvachet/pdf-chatbot' url: https://huggingface.co/spaces/cvachet/pdf-chatbot
		[4013] link 'üíª marcosv/InstructIR' url: https://huggingface.co/spaces/marcosv/InstructIR
		[4020] link 'üê≥ open-webui/open-webui' url: https://huggingface.co/spaces/open-webui/open-webui
		[4027] link 'üìâ JournalistsonHF/ai-scraper' url: https://huggingface.co/spaces/JournalistsonHF/ai-scraper
		[4034] link '‚öîÔ∏è mteb/arena' url: https://huggingface.co/spaces/mteb/arena
		[4041] link 'üíΩ Illia56/Ask-AI-Youtube' url: https://huggingface.co/spaces/Illia56/Ask-AI-Youtube
		[4048] link 'üèÉ nickmuchi/semantic-search-with-retrieve-and-rerank' url: https://huggingface.co/spaces/nickmuchi/semantic-search-with-retrieve-and-rerank
		[4055] link 'üíª nickmuchi/article-text-summarizer' url: https://huggingface.co/spaces/nickmuchi/article-text-summarizer
		[4062] link 'ü•á mteb/leaderboard_legacy' url: https://huggingface.co/spaces/mteb/leaderboard_legacy
		[4069] link 'üïØÔ∏èüî° radames/Candle-BERT-Semantic-Similarity-Wasm' url: https://huggingface.co/spaces/radames/Candle-BERT-Semantic-Similarity-Wasm
		[4076] link 'üöÄ Mr-TD/RAG-PDF-QnA-ChatBot' url: https://huggingface.co/spaces/Mr-TD/RAG-PDF-QnA-ChatBot
		[4089] button '+ 88 Spaces'